{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import words\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-30 20:50:35</td>\n",
       "      <td>1244728753617620992</td>\n",
       "      <td>14441</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>White House news conference at 5:00 P.M. Easte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-30 17:46:15</td>\n",
       "      <td>1244682364284014592</td>\n",
       "      <td>15520</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>https://t.co/2hKJkP5Z6N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-30 17:11:59</td>\n",
       "      <td>1244673740866191360</td>\n",
       "      <td>19753</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>On #NationalDoctorsDay, we recognize the remar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-30 17:05:33</td>\n",
       "      <td>1244672122414338048</td>\n",
       "      <td>39114</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>https://t.co/nzWJ8ViwbZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-30 11:17:10</td>\n",
       "      <td>1244584449309892608</td>\n",
       "      <td>43360</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Nancy Pelosi and the Democrats delayed the Wor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at               id_str  retweet_count              source  \\\n",
       "0 2020-03-30 20:50:35  1244728753617620992          14441  Twitter for iPhone   \n",
       "1 2020-03-30 17:46:15  1244682364284014592          15520  Twitter for iPhone   \n",
       "2 2020-03-30 17:11:59  1244673740866191360          19753  Twitter for iPhone   \n",
       "3 2020-03-30 17:05:33  1244672122414338048          39114  Twitter for iPhone   \n",
       "4 2020-03-30 11:17:10  1244584449309892608          43360  Twitter for iPhone   \n",
       "\n",
       "                                                text  \n",
       "0  White House news conference at 5:00 P.M. Easte...  \n",
       "1                            https://t.co/2hKJkP5Z6N  \n",
       "2  On #NationalDoctorsDay, we recognize the remar...  \n",
       "3                            https://t.co/nzWJ8ViwbZ  \n",
       "4  Nancy Pelosi and the Democrats delayed the Wor...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data loading\n",
    "path = 'C:/Users/48668/Desktop/FSS2020/DM/'\n",
    "data = pd.read_json(path + 'data.json')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract hashtags\n",
    "def hashtags(text):\n",
    "    pat = re.compile(r\"#(\\w+)\")\n",
    "    hashtags = pat.findall(text)\n",
    "    return hashtags\n",
    "\n",
    "data['hashtags'] = data.apply(lambda x: hashtags(x['text']), axis=1)\n",
    "\n",
    "# if tweet contains hashtag (boolean)\n",
    "data['if_has_hashtag'] = data.apply(lambda x: 1 if len(x['hashtags']) > 0 else 0, axis=1)\n",
    "\n",
    "# number of hashtags\n",
    "data['no_hashtag'] = data.apply(lambda x: len(x['hashtags']), axis=1)\n",
    "\n",
    "# changing float64 to string\n",
    "data['text'] = data['text'].astype(str)\n",
    "\n",
    "# remove punctuation\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        if punctuation != '!': # leave exclamation mark\n",
    "            text = text.replace(punctuation, '')\n",
    "    return text\n",
    "\n",
    "data['text'] = data.apply(lambda x: remove_punctuations(x['text']), axis=1)\n",
    "\n",
    "# remove numbers \n",
    "def remove_numbers(text):\n",
    "    return re.sub('[0-9]+', '', text)\n",
    "\n",
    "data['text'] = data.apply(lambda x: remove_numbers(x['text']), axis=1)\n",
    "\n",
    "\n",
    "# replace url with \"url\"\n",
    "def replace_urls(text):\n",
    "    return re.sub(r\"http\\S+\", \"url\", text)\n",
    "\n",
    "data['text'] = data.apply(lambda x: replace_urls(x['text']), axis=1)\n",
    "\n",
    "# remove special characters\n",
    "\n",
    "def remove_special(text):\n",
    "    for char in ['€','�','‡','†','‰','™','•']:\n",
    "        text = text.replace(char, '')\n",
    "    return text\n",
    "\n",
    "data['text'] = data.apply(lambda x: remove_special(x['text']), axis=1)\n",
    "\n",
    "# if word starts with uppercase --> lowercase, if all chars are uppercase --> do nothing\n",
    "def lower_case(text):\n",
    "    to_lowercase = lambda text: \" \".join(word if (word.isupper() == True & len(word) >= 1) else word.lower()\n",
    "            for word in text.split())\n",
    "    lowercase = to_lowercase(text)   \n",
    "    return lowercase\n",
    "\n",
    "data['text'] = data.apply(lambda x: lower_case(x['text']), axis=1)\n",
    "\n",
    "#remove elongated words\n",
    "def remove_elongated(text):\n",
    "    el = []\n",
    "    setofwords = set(words.words())\n",
    "    for word in text.split():\n",
    "        if word in setofwords:\n",
    "            pass\n",
    "        else:\n",
    "            word=re.sub(r'(?i)(.)\\1+', r'\\1', word)\n",
    "        el.append(word)\n",
    "    return el\n",
    "\n",
    "\n",
    "#data['text'] = data.apply(lambda x: remove_elongated(x['text']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>if_has_hashtag</th>\n",
       "      <th>no_hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-30 20:50:35</td>\n",
       "      <td>1244728753617620992</td>\n",
       "      <td>14441</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>white house news conference at pm eastern than...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-30 17:46:15</td>\n",
       "      <td>1244682364284014592</td>\n",
       "      <td>15520</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>url</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-30 17:11:59</td>\n",
       "      <td>1244673740866191360</td>\n",
       "      <td>19753</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>on nationaldoctorsday we recognize the remarka...</td>\n",
       "      <td>[NationalDoctorsDay]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-30 17:05:33</td>\n",
       "      <td>1244672122414338048</td>\n",
       "      <td>39114</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>url</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-30 11:17:10</td>\n",
       "      <td>1244584449309892608</td>\n",
       "      <td>43360</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>nancy pelosi and the democrats delayed the wor...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at               id_str  retweet_count              source  \\\n",
       "0 2020-03-30 20:50:35  1244728753617620992          14441  Twitter for iPhone   \n",
       "1 2020-03-30 17:46:15  1244682364284014592          15520  Twitter for iPhone   \n",
       "2 2020-03-30 17:11:59  1244673740866191360          19753  Twitter for iPhone   \n",
       "3 2020-03-30 17:05:33  1244672122414338048          39114  Twitter for iPhone   \n",
       "4 2020-03-30 11:17:10  1244584449309892608          43360  Twitter for iPhone   \n",
       "\n",
       "                                                text              hashtags  \\\n",
       "0  white house news conference at pm eastern than...                    []   \n",
       "1                                                url                    []   \n",
       "2  on nationaldoctorsday we recognize the remarka...  [NationalDoctorsDay]   \n",
       "3                                                url                    []   \n",
       "4  nancy pelosi and the democrats delayed the wor...                    []   \n",
       "\n",
       "   if_has_hashtag  no_hashtag  \n",
       "0               0           0  \n",
       "1               0           0  \n",
       "2               1           1  \n",
       "3               0           0  \n",
       "4               0           0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\48668\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aap</th>\n",
       "      <th>ab</th>\n",
       "      <th>abaco</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abba</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcnew</th>\n",
       "      <th>...</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "      <th>‚</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "      <th>„</th>\n",
       "      <th>…</th>\n",
       "      <th>‹</th>\n",
       "      <th>›</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.107300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.053141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.059762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.146762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 13714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          !  aaa  aap   ab  abaco  abandon  abba  abbott  abc  abcnew  ...  \\\n",
       "0  0.107300  0.0  0.0  0.0    0.0      0.0   0.0     0.0  0.0     0.0  ...   \n",
       "1  0.000000  0.0  0.0  0.0    0.0      0.0   0.0     0.0  0.0     0.0  ...   \n",
       "2  0.000000  0.0  0.0  0.0    0.0      0.0   0.0     0.0  0.0     0.0  ...   \n",
       "3  0.000000  0.0  0.0  0.0    0.0      0.0   0.0     0.0  0.0     0.0  ...   \n",
       "4  0.053141  0.0  0.0  0.0    0.0      0.0   0.0     0.0  0.0     0.0  ...   \n",
       "5  0.059762  0.0  0.0  0.0    0.0      0.0   0.0     0.0  0.0     0.0  ...   \n",
       "6  0.146762  0.0  0.0  0.0    0.0      0.0   0.0     0.0  0.0     0.0  ...   \n",
       "7  0.000000  0.0  0.0  0.0    0.0      0.0   0.0     0.0  0.0     0.0  ...   \n",
       "8  0.000000  0.0  0.0  0.0    0.0      0.0   0.0     0.0  0.0     0.0  ...   \n",
       "9  0.000000  0.0  0.0  0.0    0.0      0.0   0.0     0.0  0.0     0.0  ...   \n",
       "\n",
       "     —    ‘    ’    ‚    “    ”    „    …    ‹    ›  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "6  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[10 rows x 13714 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF vector extraction\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = tknzr.tokenize(text)\n",
    "    stems = []\n",
    "    for item in tokens:\n",
    "        stems.append(PorterStemmer().stem(item))\n",
    "    return stems\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize,stop_words='english')\n",
    "word_features = vectorizer.fit_transform(data['text'])\n",
    "\n",
    "vectorizer.get_feature_names()\n",
    "word_features = pd.DataFrame(word_features.todense(), columns = vectorizer.get_feature_names())\n",
    "word_features.shape\n",
    "word_features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
