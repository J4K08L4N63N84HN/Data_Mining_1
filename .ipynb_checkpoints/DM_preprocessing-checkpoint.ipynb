{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import words\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-30 20:50:35</td>\n",
       "      <td>1244728753617620992</td>\n",
       "      <td>14441</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>White House news conference at 5:00 P.M. Easte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-30 17:46:15</td>\n",
       "      <td>1244682364284014592</td>\n",
       "      <td>15520</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>https://t.co/2hKJkP5Z6N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-30 17:11:59</td>\n",
       "      <td>1244673740866191360</td>\n",
       "      <td>19753</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>On #NationalDoctorsDay, we recognize the remar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-30 17:05:33</td>\n",
       "      <td>1244672122414338048</td>\n",
       "      <td>39114</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>https://t.co/nzWJ8ViwbZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-30 11:17:10</td>\n",
       "      <td>1244584449309892608</td>\n",
       "      <td>43360</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Nancy Pelosi and the Democrats delayed the Wor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at               id_str  retweet_count              source  \\\n",
       "0 2020-03-30 20:50:35  1244728753617620992          14441  Twitter for iPhone   \n",
       "1 2020-03-30 17:46:15  1244682364284014592          15520  Twitter for iPhone   \n",
       "2 2020-03-30 17:11:59  1244673740866191360          19753  Twitter for iPhone   \n",
       "3 2020-03-30 17:05:33  1244672122414338048          39114  Twitter for iPhone   \n",
       "4 2020-03-30 11:17:10  1244584449309892608          43360  Twitter for iPhone   \n",
       "\n",
       "                                                text  \n",
       "0  White House news conference at 5:00 P.M. Easte...  \n",
       "1                            https://t.co/2hKJkP5Z6N  \n",
       "2  On #NationalDoctorsDay, we recognize the remar...  \n",
       "3                            https://t.co/nzWJ8ViwbZ  \n",
       "4  Nancy Pelosi and the Democrats delayed the Wor...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data loading\n",
    "path = 'C:/Users/48668/Desktop/DM/'\n",
    "data = pd.read_json(path + 'data.json')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "This is preprocessing section. Following steps were taken:\n",
    "\n",
    "    1. punctuation removal with '!' exception\n",
    "    2. numbers removal\n",
    "    3. url removals\n",
    "    4. normalization to lowercase with exception for isupper()\n",
    "    5. string to tokens\n",
    "    6. stopwords removal\n",
    "    7. stemming\n",
    "    8. normalization of elongated words\n",
    "\"\"\"\n",
    "\n",
    "stop_words = list(stopwords.words('english'))\n",
    "\n",
    "def remove_stop(tokens):\n",
    "    filtered = []\n",
    "    for word in tokens:\n",
    "        if word.lower() not in stop_words:\n",
    "            filtered.append(word) \n",
    "    return filtered\n",
    "\n",
    "\n",
    "# changing float64 to string\n",
    "data['text'] = data['text'].astype(str)\n",
    "\n",
    "# remove punctuation\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        if punctuation != '!': # leave exclamation mark\n",
    "            text = text.replace(punctuation, '')\n",
    "    return text\n",
    "\n",
    "# remove numbers \n",
    "def remove_numbers(text):\n",
    "    return re.sub('[0-9]+', '', text)\n",
    "\n",
    "# replace url with \"url\"\n",
    "def replace_urls(text):\n",
    "    return re.sub(r\"http\\S+\", \"url\", text)\n",
    "\n",
    "# remove special characters\n",
    "\n",
    "def remove_special(tokens):\n",
    "    t = []\n",
    "    for token in tokens:\n",
    "        if token not in ['�', 'â', '¦','€', '¤', 'à', '‡', '™','¸','Ø']:\n",
    "            t.append(token)\n",
    "    return t\n",
    "\n",
    "# if word starts with uppercase --> lowercase, if all chars are uppercase --> do nothing\n",
    "def lower_case(tokens):\n",
    "    tokens = [(w.lower() if not w.isupper() else w) for w in tokens]\n",
    "    return tokens\n",
    "\n",
    "# print(lower_case(['AAAAA', 'army', 'Army'])) # test function\n",
    "# print(remove_urls(remove_punctuations(remove_numbers('740 test test 3 99ma http://cnn.com')))) # test function\n",
    "\n",
    "#remove elongated words\n",
    "def remove_elongated(text):\n",
    "    el = []\n",
    "    setofwords = set(words.words())\n",
    "    for word in text.split():\n",
    "        if word in setofwords:\n",
    "            pass\n",
    "        else:\n",
    "            word=re.sub(r'(?i)(.)\\1+', r'\\1', word)\n",
    "        el.append(word)\n",
    "    return el\n",
    "\n",
    "#test = 'Aweeeesome president Trump greeeeat good Ameerica '\n",
    "#print(remove_elongated(test))\n",
    "\n",
    "data['text'] = data.apply(lambda x: remove_numbers(x['text']), axis=1)\n",
    "data['text'] = data.apply(lambda x: remove_punctuations(x['text']), axis=1)\n",
    "data['text'] = data.apply(lambda x: replace_urls(x['text']), axis=1)\n",
    "\n",
    "\n",
    "# tokenize\n",
    "tknzr = TweetTokenizer()\n",
    "data['tokens'] = data.apply(lambda x: tknzr.tokenize(x['text']), axis=1)\n",
    "\n",
    "# remove stop words\n",
    "data['tokens'] = data.apply(lambda x: remove_stop(x['tokens']), axis=1)\n",
    "\n",
    "# remove special char\n",
    "data['tokens'] = data.apply(lambda x: remove_special(x['tokens']), axis=1)\n",
    "\n",
    "# lower_case\n",
    "data['tokens'] = data.apply(lambda x: lower_case(x['tokens']), axis=1)\n",
    "\n",
    "# elongated words\n",
    "#data['text'] = data.apply(lambda x: remove_elongated(x['text']), axis=1)\n",
    "            \n",
    "\n",
    "# stemming\n",
    "ps = PorterStemmer() \n",
    "data['tokens'] = data.apply(lambda x: [ps.stem(w) for w in x['tokens']], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-30 20:50:35</td>\n",
       "      <td>1244728753617620992</td>\n",
       "      <td>14441</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>White House news conference at  PM Eastern Tha...</td>\n",
       "      <td>[white, hous, news, confer, PM, eastern, thank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-30 17:46:15</td>\n",
       "      <td>1244682364284014592</td>\n",
       "      <td>15520</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>url</td>\n",
       "      <td>[url]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-30 17:11:59</td>\n",
       "      <td>1244673740866191360</td>\n",
       "      <td>19753</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>On NationalDoctorsDay we recognize the remarka...</td>\n",
       "      <td>[nationaldoctorsday, recogn, remark, men, amp,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-30 17:05:33</td>\n",
       "      <td>1244672122414338048</td>\n",
       "      <td>39114</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>url</td>\n",
       "      <td>[url]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-30 11:17:10</td>\n",
       "      <td>1244584449309892608</td>\n",
       "      <td>43360</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Nancy Pelosi and the Democrats delayed the Wor...</td>\n",
       "      <td>[nanci, pelosi, democrat, delay, worker, helps...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at               id_str  retweet_count              source  \\\n",
       "0 2020-03-30 20:50:35  1244728753617620992          14441  Twitter for iPhone   \n",
       "1 2020-03-30 17:46:15  1244682364284014592          15520  Twitter for iPhone   \n",
       "2 2020-03-30 17:11:59  1244673740866191360          19753  Twitter for iPhone   \n",
       "3 2020-03-30 17:05:33  1244672122414338048          39114  Twitter for iPhone   \n",
       "4 2020-03-30 11:17:10  1244584449309892608          43360  Twitter for iPhone   \n",
       "\n",
       "                                                text  \\\n",
       "0  White House news conference at  PM Eastern Tha...   \n",
       "1                                                url   \n",
       "2  On NationalDoctorsDay we recognize the remarka...   \n",
       "3                                                url   \n",
       "4  Nancy Pelosi and the Democrats delayed the Wor...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [white, hous, news, confer, PM, eastern, thank...  \n",
       "1                                              [url]  \n",
       "2  [nationaldoctorsday, recogn, remark, men, amp,...  \n",
       "3                                              [url]  \n",
       "4  [nanci, pelosi, democrat, delay, worker, helps...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append token to vocabulary for each row\n",
    "def buildVocabulary(data):\n",
    "    \n",
    "    all_words = []\n",
    "    \n",
    "    def append_token(tokens, all_words):\n",
    "        for token in tokens:\n",
    "            all_words.append(token)\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        append_token(row[\"tokens\"],all_words)\n",
    "\n",
    "    wordlist = nltk.FreqDist(all_words)\n",
    "    \n",
    "    return wordlist\n",
    "\n",
    "a = buildVocabulary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words:\n",
      "[('!', 9400), ('url', 4321), ('great', 2728), ('RT', 2138), ('amp', 2133), ('democrat', 1450), ('presid', 1415), ('peopl', 1319), ('countri', 1155), ('thank', 1136), ('state', 1042), ('get', 1026), ('year', 906), ('new', 902), ('trump', 891), ('border', 888), ('job', 872), ('news', 867), ('fake', 860), ('big', 844), ('want', 833), ('go', 824), ('time', 815), ('work', 804), ('american', 786), ('mani', 771), ('would', 729), ('republican', 726), ('make', 710), ('never', 701), ('vote', 681), ('US', 673), ('today', 662), ('america', 633), ('even', 620), ('good', 613), ('look', 611), ('much', 600), ('one', 580), ('unit', 561), ('realdonaldtrump', 561), ('media', 550), ('like', 535), ('come', 524), ('hous', 521), ('total', 519), ('back', 518), ('deal', 512), ('done', 505), ('win', 503), ('senat', 498), ('nation', 497), ('noth', 495), ('dem', 490), ('must', 487), ('impeach', 486), ('day', 485), ('china', 480), ('elect', 474), ('report', 457), ('donâ', 445), ('see', 435), ('crime', 433), ('tax', 428), ('call', 426), ('way', 420), ('militari', 419), ('know', 413), ('secur', 411), ('bad', 410), ('made', 401), ('trade', 398), ('need', 397), ('ever', 393), ('meet', 388), ('wall', 386), ('thing', 383), ('first', 383), ('love', 375), ('take', 372), ('said', 367), ('say', 363), ('histori', 359), ('hunt', 356), ('strong', 355), ('help', 355), ('witch', 354), ('us', 349), ('also', 345), ('law', 342), ('rate', 340), ('happen', 339), ('support', 335), ('world', 333), ('russia', 329), ('congress', 328), ('hard', 327), ('honor', 326), ('last', 324), ('illeg', 322)]\n",
      "\n",
      "Total number of features: 13743\n"
     ]
    }
   ],
   "source": [
    "print(\"Most common words:\")\n",
    "print(a.most_common(100))\n",
    "\n",
    "word_features = a.keys()\n",
    "print('\\nTotal number of features: ' + str(len(word_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(tokens):\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in set(tokens))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_features'] = data.apply(lambda x: extract(x['tokens']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
